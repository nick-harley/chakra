module PPM

export A, B, C, D, X
export Interpolated, Backoff
export Bounded, Unbounded

export generate_ngrams, generate_hgrams, hgram_sequence

export Distribution, Prediction
export infcontent, entropy

export ppm, ppm_seq, ppm_seq_inc

using OptionType, Viewpoints, NGrams


### ESCAPE METHODS

abstract type Escape end

struct A <: Escape end
struct B <: Escape end
struct C <: Escape end
struct D <: Escape end
struct X <: Escape end

ppmk(::A) = 0
ppmk(::B) = -1
ppmk(::C) = 0
ppmk(::D) = -0.5
ppmk(::X) = 0

### SMOOTHING METHODS

abstract type Smoothing end

struct Interpolated <: Smoothing end
struct Backoff <: Smoothing end

### ORDER BOUNDS

abstract type OrderBound end

struct Bounded{h} <: OrderBound
    Bounded(h::Int) = h < 0 ? error("Can't have bound less than 0.") : new{h}()
end

struct Unbounded <: OrderBound end


non_nan(a::Int,b::Int)::Float64 = (x = a/b; isnan(x) ? 0 : x)

function count(g::NGram{S,T},
               tally::NGramTally{S,T},
               k::Number) where {S,T}

    # Number of occurences of g in tally plus an initial count k
    
    x = c(g,tally)

    x > 0 ? x + k : 0

end

Context{S} = SubArray{S, 1, Vector{S}, Tuple{UnitRange{Int64}}, true}

function sumcount(ctx::Context{S},
                  tally::NGramTally{S,T},
                  seen::Set{T},
                  k::Number,
                  ex::Set{T}) where {S,T}

    # The number of occurences of context ctx
    
    return sum([count(ngram(ctx,e),tally,k) for e in seen if !(e in ex)])

end

function symset(ctx::Context{S},
                tally::NGramTally{S,T},
                seen::Set{T}) where {S,T}

    # The set of symbols that have occured in context ctx

    return Set([e for e in seen if c(ngram(ctx,e),tally) > 0])
    
end

function symcount(ctx::Context{S},
                  tally::NGramTally{S,T},
                  seen::Set{T}) where {S,T}

    # The number of symbols that have occurred in context ctx

    return length(symset(ctx,tally,seen))

end

function nsymset(n::Int,
                 ctx::Context{S},
                 tally::NGramTally{S,T},
                 seen::Set{T}) where {S,T}

    # The set of symbols that have occurred n times in context ctx

    return Set([e for e in seen if c(ngram(ctx,e),tally) == n])
    
end

function nsymcount(n::Int,
                   ctx::Context{S},
                   tally::NGramTally{S,T},
                   seen::Set{T}) where {S,T}

    # The number of symbols which have occured n times in context ctx

    return length(nsymset(n,ctx,tally,seen))

end

# LAMBDA

# A 
function lambda(::A,
                ctx::Context{S},
                tally::NGramTally{S,T},
                seen::Set{T},
                ex::Set{T}) where {S,T}

    # k = 0
    
    non_nan( sumcount(ctx,tally,seen,0,ex),
             sumcount(ctx,tally,seen,0,ex) + 1)

end

# B
function lambda(::B,
                ctx::Context{S},
                tally::NGramTally{S,T},
                seen::Set{T},
                ex::Set{T}) where {S,T}

    # k = -1
    
    non_nan( sumcount(ctx,tally,seen,-1,ex),
             sumcount(ctx,tally,seen,-1,ex) + symcount(ctx,tally,seen))

end

# C
function lambda(::C,
                ctx::Context{S},
                tally::NGramTally{S,T},
                seen::Set{T},
                ex::Set{T}) where {S,T}

    # k = 0
    
    non_nan( sumcount(ctx,tally,seen,0,ex),
             sumcount(ctx,tally,seen,0,ex) + symcount(ctx,tally,seen))

end

# D
function lambda(::D,
                ctx::Context{S},
                tally::NGramTally{S,T},
                seen::Set{T},
                ex::Set{T}) where {S,T}

    # k = -0.5
    
    non_nan( sumcount(ctx,tally,seen,-0.5,ex),
             sumcount(ctx,tally,seen,-0.5,ex) + symcount(ctx,tally,seen)/2)

end

# X
function lambda(::X,
                ctx::Context{S},
                tally::NGramTally{S,T},
                seen::Set{T},
                ex::Set{T}) where {S,T}

    # k = 0
    
    non_nan( sumcount(ctx,tally,seen,0,ex),
             sumcount(ctx,tally,seen,0,ex) + nsymcount(1,ctx,tally,seen)+1) # IDYOM ADDS ONE HERE. WHY?

end



# ESTIMATE PROBABILITY



function estimate(g::NGram{S,T},
                  tally::NGramTally{S,T},
                  seen::Set{T},
                  A::Set{T},
                  B::Backoff,
                  E::Escape,
                  U::Bool,
                  ex::Set{T} = Set{T}()) where {S,T}

    n = length(g)
    
    k = ppmk(E)

    trans_count = count(g,tally,k)

    state_count = sumcount(context(g),tally,seen,k,ex)

    p = non_nan( trans_count,
                 state_count )
    
    w = lambda(E,context(g),tally,seen,ex)

    if p > 0
        return (prob = w * p,
                order = n-1)
    end 

    e = 1 - w
    
    if n == 1
        return (prob = e/(length(A)+1-length(seen)),
                order = -1)
    end          

    for e in symset(context(g),tally,seen)
        push!(ex,e)
    end
    
    p, o = estimate(trim(g,n-1),tally,seen,A,B,E,U,ex)

    return (prob = e * p,
            order = o)
end

# PPM INTERPOLATED
function estimate(g::NGram{S,T},
                  tally::NGramTally{S,T},
                  seen::Set{T},
                  A::Set{T},
                  B::Interpolated,
                  E::Escape,
                  U::Bool,
                  ex::Set{T}=Set{T}()) where {S,T}

    n = length(g)
    
    k = ppmk(E)

    trans_count = count(g,tally,k)

    state_count = sumcount(context(g),tally,seen,k,ex)

    p = non_nan( trans_count,
                 state_count )
    
    w = lambda(E,context(g),tally,seen,ex)

    e = 1 - w
    
    if n==1
        return (prob = w*p + e/(length(A)+1-length(seen)),
                order = p == 0 ? -1 : 0)
    end

    for e in symset(context(g),tally,seen)
        push!(ex,e)
    end
    
    _p, o = estimate(trim(g,n-1),tally,seen,A,B,E,U,ex)
    
    return (prob = w*p + e*_p,
            order = p == 0 ? o : n-1)
end






struct View{S,T}

    # A view of a sequence
    
    target::Vector{Option{T}}
    source::Vector{Option{S}}
    targetindex::Vector{Int}
    sourceindex::Vector{Int}
    targetelements::Vector{T}
    sourceelements::Vector{S}

    function View(elems::Vector{Tuple{Option{S},
                                      Option{T}}}) where {S,T}

        # construct a view from a vector of tuples
        
        # vector of target attribtue
        t = last.(elems)
        s = first.(elems)
        tind = findall(x->x != none,t)
        sind = findall(x->x != none,s)
        telems = t[tind]
        selems = s[sind]

        return new{S,T}(t,s,tind,sind,telems,selems)
    end

    function View(seq::Vector,
                  src::Viewpoints.Viewpoint{S},
                  trg::Viewpoints.Viewpoint{T}) where {S,T}

        # construct a view from a sequence and two viewpoints
        
        return View(Tuple{Option{S},Option{T}}[zip(vp_map(src,seq),vp_map(trg,seq))...])
    end
end

# length of a view
Base.length(v::View) = length(v.targetindex)








# Extract Ngrams from Views

function getnext(v::View{S,T},i::Int) where {S,T}
    return v.targetelements[i]
end

function getcontext(v::View{S,T},i::Int) where {S,T}
    return @views v.sourceelements[1:findfirst(s->s==v.targetindex[i],v.sourceindex)-1]
end

function getngram(v::View{S,T},i::Int) where {S,T}
    nxt = getnext(v,i)
    ctx = getcontext(v,i)
    return ngram(ctx,nxt)
end

function getngram(v::View{S,T},i::Int,n::Int) where {S,T}
    return trim(getngram(v,i),n)
end

function generate_ngrams(v::View{S,T},n::Int) where {S,T}
    return [getngram(v,i,n) for i in n:length(v)]
end

# GENERATE HGRAMS

function generate_hgrams(v::View{S,T},h::Int)::Vector{NGram{S,T}} where {S,T}
    vcat([generate_ngrams(v,n) for n in 1:h]...)
end

generate_hgrams(v::View,::Bounded{b}) where b = generate_hgrams(v,b+1)

generate_hgrams(v::View) = generate_hgrams(v,length(v)) 

generate_hgrams(v::View,::Unbounded) = generate_hgrams(v)

# HGRAM SEQUENCE

hgram_sequence(v::View) = begin
    return [getngram(v,i) for i in 1:length(v)]
end

hgram_sequence(v::View,h::Int) = begin
    return [getngram(v,i,h) for i in 1:length(v)]
end

hgram_sequence(v::View,::Bounded{b}) where b = begin
    hgram_sequence(v,b+1)
end

hgram_sequence(v::View,::Unbounded) = begin
    hgram_sequence(v)
end

function select_order(v::View{S,T},
                      i::Int,
                      tally::NGramTally{S,T},
                      seen::Set{T},
                      O::Bounded{h}) where {S,T,h}
    return getngram(v,i,h)
end


function select_order(v::View{S,T},
                      i::Int,
                      tally::NGramTally{S,T},
                      seen::Set{T},
                      O::Unbounded) where {S,T}

    nxt = getnext(v,i)
    ctx = getcontext(v,i)

    if length(ctx) == 0
        return ngram(ctx,nxt)
    end
    #_ctx = S[]
    for l in 0:length(ctx)
        @views _ctx = ctx[end-l+1:end]
        cnt = symcount(_ctx,tally,seen)
        if cnt == 1
            # Smallest deterministic context
            return ngram(_ctx,nxt)
        end
        if cnt == 0
            # Largest matching context
            return @views ngram(_ctx[2:end],nxt)
        end
    end

    return ngram(ctx,nxt)

end



using Distributions

struct Prediction{T}
    symbol::T
    distribution::Distribution{T}
    estimate::Float64
    order::Int
end

infcontent(x::Prediction) = Distributions.infcontent(x.distribution,x.symbol)
entropy(x::Prediction) = Distributions.entropy(x.distribution)
max_entropy(x::Prediction) = Distributions.max_entropy(x.distribution)
relative_entropy(x::Prediction) = Distributions.relative_entropy(x.distribution)
weight(x::Prediction,b::Int) = Distributions.weight(x.distribution,b)
mean_infcontent(ps::Vector{Prediction}) = sum([infcontent(p) for p in ps])/length(ps)


function combine(ps;b)
    sym = ps[1].symbol
    ds = [p.distribution for p in ps]
    os = [p.order for p in ps]
    new_dist = Distributions.combine(ds;b=b)
    p = new_dist(sym)
    o = max(os...)
    Prediction(sym,new_dist,p,o)
end


# PREDICT



function ppm(g::NGram{S,T},
             tally::NGramTally{S,T},
             seen::Set{T},
             A::Set{T},
             B::Smoothing,
             E::Escape,
             U::Bool) where {S,T}

    p,o = estimate(g,tally,seen,A,B,E,U)

    dist = Distribution(Dict([(e,estimate(ngram(context(g),e),tally,seen,A,B,E,U)[1]) for e in A]))
    
    return Prediction(next(g),dist,p,o)
    
end



struct PPMParameters
    alphabet::Set
    smoothing::Smoothing
    escape::Escape
    exclusion::Bool
end

struct PPMModel
    view::View
    parameters::PPMParameters
    distributions::Vector{Distribution}

end



# MODEL A SEQUENCE



function ppm_seq(v::View{S,T},
                 tally::NGramTally{S,T},
                 seen::Set{T},
                 A::Set{T},
                 B::Smoothing,
                 E::Escape,
                 U::Bool,
                 O::OrderBound) where {S,T}
    
    return Prediction{T}[ppm(select_order(v,i,tally,seen,O),tally,seen,A,B,E,U) for i in 1:length(v)]
end



# MODEL A SEQUENCE INCREMENTALLY



function ppm_seq_inc(v::View{S,T},
                     A::Set{T},
                     B::Smoothing,
                     E::Escape,
                     U::Bool,
                     O::OrderBound;
                     tally = NGramTally{S,T}(),
                     seen = Set{T}()) where {S,T,h}

    predictions = Prediction{T}[]
    
    for i in 1:length(v)
        g = select_order(v,i,tally,seen,O)
        push!(predictions,ppm(g,tally,seen,A,B,E,U))
        updatetally(tally,getngram(v,i))
        push!(seen,next(g))
    end
    
    return predictions
    
end



# DATASET MANAGEMENT



function folddataset(data::Vector{View{S,T}},
                     nfolds::Int) where {S,T}

    size = length(data)
    if !(0 < nfolds <= size)
        error("The number of folds must be less than the size of the data set size.")
    end

    folds = Int[Int(round(i/nfolds % 1 *nfolds)) for i in 1:size]
    folds[findall(x->x==0,folds)] .= nfolds

    folds = sort(folds)
    
    training_sets = Vector{View{S,T}}[data[findall(x->x != i,folds)] for i in 1:nfolds]
    
    return folds, training_sets

end

function train(examples::Vector{View{S,T}},O::OrderBound) where {S,T}

    # Create an ngram tally and a set of seen elements of T
    
    gs = vcat([generate_hgrams(ex,O) for ex in examples]...)
    seen = Set([next(g) for g in gs])
    tally = maketally(gs)
    return tally, seen
end



# BUILD MODELS


function ppm_stm(data::Vector{View{S,T}},
                 A::Set{T},
                 B::Smoothing,
                 E::Escape,
                 U::Bool,
                 O::OrderBound) where {S,T}

    # Build short term model
    
    return Vector{Prediction{T}}[ppm_seq_inc(v,A,B,E,U,O) for v in data]

end


function ppm_ltm(data::Vector{View{S,T}},
                 A::Set{T},
                 B::Smoothing,
                 E::Escape,
                 U::Bool,
                 O::OrderBound,
                 nfolds::Int=10)::Vector{Vector{Prediction{T}}} where {S,T}

    # Build long term model
    
    size = length(data)

    #print("Folding dataset...\n")
    @time folds, training = folddataset(data,nfolds)
    #print("Folding complete!\n")
    
    #print("Creating dbs...\n")
    @time db = [train(t,O) for t in training]
    #print("Training complete!\n")

    tally = first.(db)
    seen = last.(db)

    #print("Predicting...")
    #models = Vector{Prediction{T}}[]
    #for i in 1:size
    #    @time @views push!(models,ppm_seq(data[i],tally[folds[i]],seen[folds[i]],A,B,E,U,O))
        #print("Sequence Complete!")
    #end
    return @views [ppm_seq(data[i],tally[folds[i]],seen[folds[i]],A,B,E,U,O) for i in 1:size]
end


function ppm_ltm_plus(data::Vector{View{S,T}},
                      A::Set{T},
                      B::Smoothing,
                      E::Escape,
                      U::Bool,
                      O::OrderBound,
                      nfolds::Int=10) where {S,T}


    # Build long term + model

    folds, training = folddataset(data,nfolds)

    db = [train(t,O) for t in training]
    # Should fresh tallies be used for each test set? 
    return [ppm_seq_inc(data[i],A,B,E,U,O; tally = db[folds[i]][1], seen = db[folds[i]][2]) for i in 1:length(data)]
end



function ppm_both(data::Vector{View{S,T}},
                  A::Set{T},
                  B::Smoothing,
                  E::Escape,
                  U::Bool,
                  O::OrderBound,
                  nfolds::Int=10,
                  b::Int=0) where {S,T}

    # Combine LTM and STM models
    
    stm = ppm_stm(data,A,B,E,U,O)
    ltm = ppm_ltm(data,A,B,E,U,O,nfolds)

    return [[combine(Prediction[p1,p2];b=b) for (p1,p2) in zip(s,l)] for (s,l) in zip(stm,ltm)]
end

function ppm_both_plus(data::Vector{View{S,T}},
                       A::Set{T},
                       B::Smoothing,
                       E::Escape,
                       U::Bool,
                       O::OrderBound,
                       nfolds::Int=10,
                       b::Int=0) where {S,T}

    # Combine LTM+ and STM models
    
    stm = ppm_stm(data,A,B,E,U,O)
    ltm = ppm_ltm_plus(data,A,B,E,U,O,nfolds)

    return [[combine(Prediction[p1,p2];b=b) for (p1,p2) in zip(s,l)] for (s,l) in zip(stm,ltm)]
end





using DataFrames

function todataframe(id::Int,ps::Vector{Prediction{T}}) where {T}
    seqid = repeat([id],length(ps))
    eventid = [1:length(ps)...]
    sym = [p.symbol for p in ps]
    ord = [p.order for p in ps]
    prob = [p.distribution(p.symbol) for p in ps]
    ic = infcontent.(ps)
    en = entropy.(ps)

    return DataFrame(SeqID = seqid,
                     EventID = eventid,
                     Symbol = sym,
                     Order = ord,
                     Prob = prob,
                     IC = ic,
                     H = en)

end

function todataframe(ps::Vector{Vector{Prediction{T}}}) where {T}
    vcat([todataframe(i,p) for (i,p) in enumerate(ps)]...)
end




# end of module
end
